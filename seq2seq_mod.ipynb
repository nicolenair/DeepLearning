{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNmqYO8hxoAg"
   },
   "source": [
    "# Approach\n",
    "\n",
    "In this assignment, I used the seq2seq model with attention (usually used for machine translation) to get harmonize the melody line. I assumed that the highest pitch played at any one moment is the melody (as it is often true in vocal music — which is what I used as my training data — that the soprano/highest voice sings the melody). Therefore, each input is comprised of 5 notes in the melody and the output is all the other notes played at the same time (the harmony). Each note in the input is represented as a stringified midi pitch (so a number representing the pitch) and the output is represented as a stringified one-hot-encoding of notes present in the harmony. To be clear, the notes incorporate octave information as well (if not it would be trivial to map from a melody note to harmony notes, given that the harmony notes are just notes in the same chord). By including octave information, the seq2seq model has to learn which direction the harmony moves in as well (or the bass notes for the harmony etc.)\n",
    "\n",
    "Example input: 67 67 67 67 67 \t\n",
    "\n",
    "Example output: 000000000000000000000100000000000000010010000100000000000000000000000000000000000000000 000000000000000000000100000000000000010010000100000000000000000000000000000000000000000 000000000000000000000100000000000000010010000100000000000000000000000000000000000000000 000000000000000000000100000000000000010010000100000000000000000000000000000000000000000 000000000000000000000000000000000100010010000100000000000000000000000000000000000000000 \n",
    "\n",
    "For the model code, I reused code from [this tutorial](https://kern.humdrum.org/cgi-bin/ksbrowse?type=collection&l=/users/craig/classical/bach/371chorales) by Robertson (n.d.). The code was originally used for machine translation, so I just preprocessed my input data to fit the input required by the machine translation code. I comment on any modifications I made, as well as on the architecture of the model in the cells.\n",
    "\n",
    "Although at first glance, music generation might seem a bad candidate for using seq2seq because seq2seq lacks the diversity of outputs produced by some other RNN models (it tries to maximise the probability of the prediction), I think it is appropriate for harmonization because of the limited scope of possible outputs i.e. we are not trying to \"generate\" a new melody, we are trying to translate a melody into its harmony. \n",
    "\n",
    "# Data\n",
    "\n",
    "I used 50 chorales written by Bach as my input data (though each chorale was split up into one-shifted sequences of 5 yielding 121120 input-output pairs). The chorales contain four voices, and I used the highest voice as input data, whist using the other voices as output data. [Link to dataset](https://kern.humdrum.org/cgi-bin/ksbrowse?type=collection&l=/users/craig/classical/bach/371chorales). \n",
    "\n",
    "# Architecture of Seq2Seq\n",
    "\n",
    "I used a seq2seq model, which is composed of two recurrent neural networks i.e. an encoder and a decoder. The encoder takes the input sequence (here a sequence of midi pitch notes) and produces an embedding for it. This embedding is taken as input to the decoder which tries to predict the output sequence, also using information from the previous output word. \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ZthW4u9gsG7yAPdv355W1l9N1VR7PLi-\" style=\"width:700px;\">\n",
    "\n",
    "image source: [Generative-Model-Chatbots](https://medium.com/botsupply/generative-model-chatbots-e422ab08461e)\n",
    "\n",
    "\n",
    "# Results\n",
    "I ran the model for 300000 iterations (which took about 2 hours on the Colab GPU). \n",
    "\n",
    "The audio results (recorded at every 5000th iteration) can be found in this folder: [Folder](https://drive.google.com/drive/folders/1F9ejRX1aQrG5_wsp8jL-Ow6ZJZJRh_LF?usp=sharing). See loss below.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1t6wJJL9m8NuNOHGJI2egXVFAZnFtrLDA\" style=\"width:500px;\">\n",
    "\n",
    "# Interpretation of results\n",
    "\n",
    "A good sign is that we do not have generated samples that also appeared in the training samples (i.e. we do not have the same sequence of harmonies appearing in the input, which means our model is not just memorizing training data). [Note: I think that my code which checks for this working fine, but I personally find this statement hard to believe, because it seems unlikely that there are not more repetitions in a 5-note sequence output set, especially as we are using a translation model, and not a model that incorporates more randomness/ is trained for diversity].\n",
    "\n",
    "Comparing samples from the 5000th iteration and the 300000th iteration, we can hear that the 5000th iteration model already produces consonant harmonies. However, the main thing I noticed is that the model from the 295000th epoch in contrast, is sophisticated enough to play more complicated chords rather than only easier chords (using the first, third and fifth notes on a musical scale for example). An example of sophistication is when it experimented with a A#7 chord in 300000_17.wav as well as G#m6 in 300000_23.wav\n",
    "\n",
    "As a sanity check, I tried the model on 5 randomly chosen sequences from 5 chorales that were not in the training data, to see if reasonable results were produced. You can listen to the results here, but they are indeed quite reasonable: [Folder](https://drive.google.com/open?id=1ubm9lZfkEH9d7sDOvK9b3-vkuIouifwI)\n",
    "\n",
    "I suppose one weakness of this paper is that I do not quantitatively evaluate the results using something like an augmented BLEU score.\n",
    "\n",
    "Furthermore, it is a little hard to tell if generated samples indicate mode collapse, because there are a quantifiable number of transitions that might be made from one time step to another without causing dissonance.\n",
    "\n",
    "# References\n",
    "\n",
    "Robertson, S. (n.d.). NLP from Scratch: Translation with a Sequence-to-Sequence Network and Attention. Retrieved from https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "cpmpercussion(2019), creative-prediction,  https://github.com/cpmpercussion/creative-prediction/blob/master/notebooks/3-zeldic-musical-RNN.ipynb\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOZ2jo9GxmQ5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "rsdDkV5nCzth",
    "outputId": "e844cc36-bb8a-4d7b-bc35-9a282ef2beb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/content/drive/My Drive')\n",
    "#mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qC-5ToBMw2gB"
   },
   "outputs": [],
   "source": [
    "#preprocess data\n",
    "# I modified the function streamToNoteArray from this repo: \\\n",
    "#https://github.com/cpmpercussion/creative-prediction/blob/master/\\\n",
    "#notebooks/3-zeldic-musical-RNN.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from music21 import converter, instrument, note, chord, stream, midi\n",
    "\n",
    "\n",
    "MELODY_NOTE_OFF = 128 # (stop playing all previous notes)\n",
    "MELODY_NO_EVENT = 129 # (no change from previous event)\n",
    "# process the ties\n",
    "\n",
    "#use function to stream the data from midi file (already converted \n",
    "#to music21) \n",
    "#to an array of notes\n",
    "def streamToNoteArray(stream):\n",
    "    # Part one, extract from stream\n",
    "    total_length = np.int(np.round(stream.flat.highestTime / 0.25))\n",
    "     # in semiquavers\n",
    "    stream_list = []\n",
    "    for element in stream.flat:\n",
    "        if isinstance(element, note.Note):\n",
    "            stream_list.append([np.round(element.offset / 0.25), \\\n",
    "                                np.round(element.quarterLength / 0.25)\\\n",
    "                                , element.pitch.midi])\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            stream_list.append([np.round(element.offset / 0.25), \\\n",
    "                                np.round(element.quarterLength / 0.25),\\\n",
    "                                element.sortAscending().pitches[-1].midi])\n",
    "    np_stream_list = np.array(stream_list, dtype=np.int)\n",
    "    return(np_stream_list)\n",
    "\n",
    "#\n",
    "songs = []\n",
    "for i in range(1, 51):\n",
    "  if len(str(i))==1:\n",
    "    e = \"00\" + str(i)\n",
    "  elif len(str(i))==2:\n",
    "    e = \"0\" + str(i)\n",
    "  else:\n",
    "    e = str(i)\n",
    "  song = converter.parse('bach/chor{}.midi'.format(e))\n",
    "  songs.append(streamToNoteArray(song))\n",
    "\n",
    "#make the data into a dataframe\n",
    "columns = [\"id\", \"st\", \"dur\", \"pitch\"]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "df\n",
    "for i in range(len(songs)):\n",
    "  for e in range(len(songs[i])):\n",
    "    df = df.append({\"id\":i, \"st\":songs[i][e][0], \"dur\":songs[i][e][1],\\\n",
    "                    \"pitch\":songs[i][e][2]}, ignore_index = True)\n",
    "d = df\n",
    "\n",
    "#make a new dataframe that has a row for each time step where\n",
    "# notes play\n",
    "col_dur = [\"id\"] + [\"timestep\"] + [\"soprano\"] + [str(i) for \\\n",
    "                                                 i in range(22, \\\n",
    "                                                            109)]\n",
    "duration_df = pd.DataFrame(columns = col_dur)\n",
    "\n",
    "#so I know when a note is no longer played\n",
    "d[\"end\"] = d[\"st\"].add(d[\"dur\"])\n",
    "\n",
    "for i in range(len(d[\"id\"].unique())):\n",
    "  for time in range(max(d[d[\"id\"] == d[\"id\"].unique()[i]][\"end\"])):\n",
    "    # print(time)\n",
    "    rows = d[d[\"id\"]==d[\"id\"].unique()[i]][(d[d[\"id\"]==d[\"id\"].\\\n",
    "                                              unique()[i]][\"st\"]\\\n",
    "                                            <=time) &  (d[d[\"id\"]==\\\n",
    "                                                          d[\"id\"].unique\\\n",
    "                                                          ()[i]][\"end\"]>\\\n",
    "                                                        time)]\n",
    "    if rows.empty==False:\n",
    "      soprano = max(rows[\"pitch\"])\n",
    "      dict_to_add_row = {\"id\": d[\"id\"].unique()[i], \"timestep\":\\\n",
    "                         time, \"soprano\":soprano}\n",
    "      for k in range(22, 109):\n",
    "        dict_to_add_row[str(k)] = 0\n",
    "      for note in rows[\"pitch\"]:\n",
    "        dict_to_add_row[str(note)]=1\n",
    "      duration_df = duration_df.append(dict_to_add_row, \\\n",
    "                                       ignore_index = True)\n",
    "\n",
    "\n",
    "data = duration_df\n",
    "\n",
    "data_inputs = []\n",
    "data_outputs = []\n",
    "for i in data.iloc[:,0].unique():\n",
    "  for e in range(len(data[data.iloc[:,0]==i])):\n",
    "    b = list(data[data.iloc[:,0]==i].iloc[:,2][e:e+5])\n",
    "    c = \"\"\n",
    "    for j in range(len(b)):\n",
    "      c = c + str(b[j])+ \" \"\n",
    "    data_inputs.append(c)\n",
    "    data_outputs.append(data[data.iloc[:,0]==i].iloc[:,3:90].\\\n",
    "                        iloc[e:e+5])\n",
    "\n",
    "all_output_seq = []\n",
    "for sequence in range(len(data_outputs)):\n",
    "  curr_seq = \"\"\n",
    "  for i in range(len(data_outputs[sequence])):\n",
    "    curr_seq = curr_seq + \"\".join([str(s) for s in list(data_outputs\\\n",
    "                                                        [sequence].\\\n",
    "                                                        iloc[i])])\n",
    "    curr_seq = curr_seq+\" \"\n",
    "  all_output_seq.append(curr_seq)\n",
    "\n",
    "#write to text file in input-output tab separated format for input\\\n",
    " into seq2seq\n",
    "file = open(\"data/bass-harmony.txt\", \"w\")\n",
    "for i in range(len(data_inputs)):\n",
    "  file.write(data_inputs[i] + \"\\t\" + all_output_seq[i])\n",
    "  file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvY_hfatCRFU"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "# !pip install music21\n",
    "import music21\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBTKLiARCRFY"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "#maps from notes/chords to index\n",
    "#similar to mapping words in a vocab to index\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7xMzlJrhCRFe"
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs\n",
    "    pairs = [[s for s in l.split('\\t')] for l in lines] \n",
    "    #i do not normalize strings like tutorial, unnecessary\n",
    "    #for my application\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "do2-8j1ICRFh"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filterPair(p):\n",
    "    return True\n",
    "\n",
    "#i do not do any filtering\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "15SFsbDxCRFk",
    "outputId": "dcae016c-4705-4271-8e80-65ef94d8b5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 12212 sentence pairs\n",
      "Trimmed to 12212 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "bass 24\n",
      "harmony 1571\n",
      "['71 69 69 67 67 ', '000000000000000000000000000000000100010000000000010000000000000000000000000000000000000 000000000000000000000000000000001001000100000001000000000000000000000000000000000000000 000000000000000000000000000000001001000100000001000000000000000000000000000000000000000 000000000000000000000000000010000000010010000100000000000000000000000000000000000000000 000000000000000000000000000010000000010010000100000000000000000000000000000000000000000 ']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2,\\\n",
    "                                               reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('bass', \\\n",
    "                                             'harmony', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2D68oYVCRFo"
   },
   "outputs": [],
   "source": [
    "#defining encoder with a hidden layer, an embedding layer\n",
    "# and a gru layer\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WwaztqNCRFs"
   },
   "outputs": [],
   "source": [
    "#basic decoder to map from output of encoder to prediction\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLcEMcjZCRFv"
   },
   "outputs": [],
   "source": [
    "#decoder but with attention, notice the extra\n",
    "#linear and dropout layers\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1,\\\n",
    "                 max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8Bbi-dDCRFy"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, \\\n",
    "                        device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "#just to convert training pairs to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHsxqtQ5CRF1"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,\\\n",
    "          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, \\\n",
    "                                  encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < \\\n",
    "    teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  \n",
    "            # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-z0pidVCRF4"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jFh0jw05lNbm"
   },
   "outputs": [],
   "source": [
    "#wrote this code to generate outputted predictions\n",
    "#and then convert to abc so we can listen to it\n",
    "pitches = list(range(22, 109))\n",
    "\n",
    "notes = []\n",
    "for oct_ in range(9):\n",
    "  notes_beg = [\"A{}\".format(oct_), \"^A{}\".format(oct_), \\\n",
    "               \"B{}\".format(oct_), \"C{}\".format(oct_+1), \\\n",
    "               \"^C{}\".format(oct_+1), \"D{}\".format(oct_+1),\\\n",
    "               \"^D{}\".format(oct_+1), \"E{}\".format(oct_+1), \\\n",
    "               \"F{}\".format(oct_+1), \"^F\".format(oct_+1), \\\n",
    "               \"G{}\".format(oct_+1), \"^G{}\".format(oct_+1)]\n",
    "  notes.extend(notes_beg)\n",
    "notes = notes[:87]\n",
    "note_index = dict(zip(pitches, notes))\n",
    "inv_note_index = {v: k for k, v in note_index.items()}\n",
    "\n",
    "import re\n",
    "def convert_bin_to_chord(binary):\n",
    "  output = []\n",
    "  list_ = binary.split(\" \")\n",
    "  n_output_words = []\n",
    "  for i in list_:\n",
    "    if i!=\"\" and i!=\"<EOS>\":\n",
    "      n_output_words.append(i)\n",
    "  output_words = n_output_words\n",
    "  for i in range(len(output_words)):\n",
    "    c = []\n",
    "    for e in re.finditer(\"1\", output_words[i]):\n",
    "      c.append(e.start() + 22)\n",
    "    c = sorted(c)\n",
    "    chord = [note_index[int(n)] for n in c]\n",
    "    output.append(\"\".join(chord))\n",
    "  return output\n",
    "\n",
    "#this name is a little misleading bc we are converting to abc, \n",
    "#not midi yet\n",
    "def convert_to_midi(encoder, decoder, random_=1, pair = []):\n",
    "        if random_==1:\n",
    "          pair = random.choice(pairs)\n",
    "          notes_in_ori = pair[1]\n",
    "          output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "          output_sentence = ' '.join(output_words)\n",
    "          output= convert_bin_to_chord(output_sentence)\n",
    "          true_out = convert_bin_to_chord(notes_in_ori)\n",
    "          if output_sentence[:-5] not in [i[1] for i in pairs]:\n",
    "            print(\"not a duplicate!\")\n",
    "          return output, true_out\n",
    "        else:\n",
    "          pair = pair\n",
    "          notes_in_ori = pair[1]\n",
    "          output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "          output_sentence = ' '.join(output_words)\n",
    "          output= convert_bin_to_chord(output_sentence)\n",
    "          true_out = convert_bin_to_chord(notes_in_ori)\n",
    "          if output_sentence[:-5] not in [i[1] for i in pairs]:\n",
    "            print(\"not a duplicate!\")\n",
    "          return output, true_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KO2hlbxCRF6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, \\\n",
    "               plot_every=100, learning_rate=0.01, i_start = 0):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            torch.save(encoder.state_dict(), \"enc_bass_harm\")\n",
    "            torch.save(decoder.state_dict(), \"dec_bass_harm\")\n",
    "            with open(\"output{}.txt\".format(iter+i_start), \"w\") as file:\n",
    "              for y in range(5):\n",
    "                out_abc, true = convert_to_midi(encoder, decoder)\n",
    "                file.write(str(y))\n",
    "                file.write(\"\\n\")\n",
    "                for e in out_abc:\n",
    "                  file.write(e)\n",
    "                  file.write(\"\\n\")\n",
    "\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100,\\\n",
    "                                         print_loss_avg))\n",
    "            if iter+i_start!=1:\n",
    "              with open(\"loss.txt\", \"a+\") as file:\n",
    "                file.write(str(print_loss_avg))\n",
    "                file.write(\"\\n\")\n",
    "            else:\n",
    "              with open(\"loss.txt\", \"w\") as file:\n",
    "                file.write(str(print_loss_avg))\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "            #i write loss to file instead of directly plotting\n",
    "            #i also save the latest model to file and 5 samples every \n",
    "            #5000 iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApplN7sGCRGC"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, \\\n",
    "                                      encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tdWN_vE8CRGL",
    "outputId": "3d4755bb-94bd-46dc-eb4c-56a6ccd066cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "2m 7s (- 61m 42s) (5000 3%) 1.8801\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "4m 0s (- 56m 12s) (10000 6%) 1.8666\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "5m 55s (- 53m 18s) (15000 10%) 1.8705\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "7m 50s (- 50m 55s) (20000 13%) 1.8498\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "9m 42s (- 48m 32s) (25000 16%) 1.8187\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "11m 36s (- 46m 27s) (30000 20%) 1.8386\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "13m 31s (- 44m 26s) (35000 23%) 1.8496\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "15m 28s (- 42m 34s) (40000 26%) 1.8160\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "17m 22s (- 40m 32s) (45000 30%) 1.8338\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "19m 16s (- 38m 33s) (50000 33%) 1.8053\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "21m 9s (- 36m 32s) (55000 36%) 1.7813\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "23m 1s (- 34m 31s) (60000 40%) 1.8012\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "24m 53s (- 32m 33s) (65000 43%) 1.7970\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "26m 48s (- 30m 37s) (70000 46%) 1.7962\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "28m 43s (- 28m 43s) (75000 50%) 1.7847\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "30m 35s (- 26m 46s) (80000 53%) 1.7749\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "32m 29s (- 24m 51s) (85000 56%) 1.7990\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "34m 24s (- 22m 56s) (90000 60%) 1.7912\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "36m 16s (- 21m 0s) (95000 63%) 1.7763\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "38m 12s (- 19m 6s) (100000 66%) 1.7592\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "40m 5s (- 17m 10s) (105000 70%) 1.7937\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "41m 57s (- 15m 15s) (110000 73%) 1.7823\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "43m 53s (- 13m 21s) (115000 76%) 1.7974\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "45m 46s (- 11m 26s) (120000 80%) 1.8003\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "47m 38s (- 9m 31s) (125000 83%) 1.7707\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "49m 31s (- 7m 37s) (130000 86%) 1.7863\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "51m 23s (- 5m 42s) (135000 90%) 1.7959\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "53m 16s (- 3m 48s) (140000 93%) 1.7543\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "55m 10s (- 1m 54s) (145000 96%) 1.7822\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "not a duplicate!\n",
      "57m 2s (- 0m 0s) (150000 100%) 1.7713\n"
     ]
    }
   ],
   "source": [
    "# hidden_size = 256\n",
    "# encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, \\\n",
    "#dropout_p=0.1).to(device)\n",
    "trainIters(encoder1, attn_decoder1, 150000, \\\n",
    "           print_every=5000, i_start = 150000)\n",
    "\n",
    "#if we comment out the first three lines, we can continue training\n",
    "#after stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iF1Krtn8m5xX"
   },
   "outputs": [],
   "source": [
    "#i commented it out bc it produces lots of text\n",
    "#saying things the midi is being rendered to wav\n",
    "\n",
    "# !apt install fluidsynth\n",
    "# !cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
    "# import re\n",
    "# import music21\n",
    "# #convert to midi then to wav for easy listening\n",
    "\n",
    "# i_start = 150000 #change this to latest iter for start training\n",
    "# for i in list(range(0, 150001))[::5000]:\n",
    "#   print(\"iter: \", i+i_start)\n",
    "#   out_abc = []\n",
    "#   file = open(\"output{}.txt\".format(i+i_start), \"r\")\n",
    "#   for en, e in enumerate(file.readlines()[1:]):\n",
    "#     if re.match(\"[0-9]+\", e)==None:\n",
    "#       out_abc.append(e[:-1])\n",
    "#     else:\n",
    "#       print(out_abc)\n",
    "#       #play\n",
    "#       if len(out_abc)==5:\n",
    "#         abcStr = ('M:5/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#             'snm=\"wh\"\\n[{}] [{}] [{}] [{}] [{}] ||\\nV:2 name=\"piano\" '.\\\n",
    "#             format(out_abc[0], out_abc[1], out_abc[2], out_abc[3],out_abc[4]))\n",
    "#       elif len(out_abc)==4:\n",
    "#           abcStr = ('M:4/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#             'snm=\"wh\"\\n[{}] [{}] [{}] [{}]||\\nV:2 name=\"piano\" '.\\\n",
    "#             format(out_abc[0], out_abc[1], out_abc[2], out_abc[3]))\n",
    "#       elif len(out_abc)==3:\n",
    "#           abcStr = ('M:3/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#             'snm=\"wh\"\\n[{}] [{}] [{}]||\\nV:2 name=\"piano\" '.format\\\n",
    "#             (out_abc[0], out_abc[1], out_abc[2]))\n",
    "#       elif len(out_abc)==2:\n",
    "#           abcStr = ('M:2/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#             'snm=\"wh\"\\n[{}] [{}]||\\nV:2 name=\"piano\" '.format\\\n",
    "#             (out_abc[0], out_abc[1]))\n",
    "#       elif len(out_abc)==1:\n",
    "#           abcStr = ('M:4/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#             'snm=\"wh\"\\n[{}] ||\\nV:2 name=\"piano\" '.format\\\n",
    "#             (out_abc[0]))\n",
    "#       out = music21.converter.parse(abcStr).write(\"midi\")\n",
    "#       ie = str(i)\n",
    "#       o = 'bach_out/{}_{}.wav'.format(i+i_start, en)\n",
    "#       !fluidsynth -ni font.sf2 $out -F $o -r 44100\n",
    "#       from IPython.display import Audio\n",
    "#       Audio('bach_out/{}_{}.wav'.format(i+i_start, en))\n",
    "#       #reset for next sample\n",
    "#       out_abc = []\n",
    "    \n",
    "  \n",
    "\n",
    "#   #generate\n",
    "#   # out_abc, true = convert_to_midi(encoder1, attn_decoder1)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "wKsoRtNTgZpg",
    "outputId": "65a2c81c-6f47-4017-f5f6-a80c4ee89705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'avg_loss/5000 iters')"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwwAAAILCAYAAABFDRt3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/gtDD4QNOJAKMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 261,
       "width": 390
      },
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "losses = []\n",
    "with open(\"loss.txt\", \"r\") as file:\n",
    "  for e in file.readlines():\n",
    "    losses.append(float(e[:-1]))\n",
    "\n",
    "plt.plot(list(range(5000, 300001))[::5000], losses)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"avg_loss/5000 iters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lo-fNSlGCXHL"
   },
   "outputs": [],
   "source": [
    "# #code to reload saved model & test on test set\n",
    "#i commented it out bc it produces lots of text\n",
    "#saying things the midi is being rendered to wav\n",
    "# !apt install fluidsynth\n",
    "# !cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
    "# inp = ['74 72 72 72 72 ', '69 69 69 69 69 ', '67 67 67 72 72 ',\\\n",
    "#        '73 71 71 71 71 ', '67 67 67 67 67 ']\n",
    "# outp = ['000000000000000000000000000000001000000000100000100100000000000000000000000000000000000 000000000000000000000000010000000000000001001000010000000000000000000000000000000000000 000000000000000000000000010000000000000001001000010000000000000000000000000000000000000 000000000000000000000000010000000000000001001000010000000000000000000000000000000000000 000000000000000000000000010000000000000001001000010000000000000000000000000000000000000 ', '000000000000000000000000010000000000000010000010010000000000000000000000000000000000000 000000000000000000000000010000000000000010000010010000000000000000000000000000000000000 000000000000000000000000010000000000000010001000010000000000000000000000000000000000000 000000000000000000000000010000000000000010001000010000000000000000000000000000000000000 000000000000000000010000000000000000000100000010000100000000000000000000000000000000000 ', '000000000000000000000000000000000001000010000000010010000000000000000000000000000000000 000000000000000000000000000000000001000010000000010010000000000000000000000000000000000 000000000000000000000000000000000000100100000000000100100000000000000000000000000000000 000000000000000000000000000000000000100100000000000100100000000000000000000000000000000 000000000000000000000000000000000000100000001000000100100000000000000000000000000000000 ', '000000000000000000000000100000000000000010010000100000000000000000000000000000000000000 000000000000000000000000100000000000000010010000100000000000000000000000000000000000000 000000000000000000000000100000000000000010010000100000000000000000000000000000000000000 000000000000000000000000100000000000000010010000100000000000000000000000000000000000000 000000000000000000000000100000000000000010010000100000000000000000000000000000000000000 ', '000000000000000000000000000000001001000010000001000000000000000000000000000000000000000 000000000000000000000000000000001001000010000001000000000000000000000000000000000000000 000000000000000000000000000000000100010010000001000000000000000000000000000000000000000 000000000000000000000000000000000100010010000001000000000000000000000000000000000000000 000000000000000000000000000000000001000100000001000000000000000000000000000000000000000 ']\n",
    "\n",
    "# #i did the preprocessing for the test set similar to the training set \n",
    "# for i in range(len(inp)):\n",
    "#   hidden_size = 256\n",
    "#   encoder2 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "#   decoder2 = AttnDecoderRNN(hidden_size, 1547, dropout_p\\\n",
    "#                             =0.1).to(device)\n",
    "\n",
    "#   encoder2.load_state_dict(torch.load(\"enc_bass_harm\"))\n",
    "#   decoder2.load_state_dict(torch.load(\"dec_bass_harm\"))\n",
    "\n",
    "#   out_abc, true = convert_to_midi(encoder2, decoder2, 0, (inp[i], outp[i]))\n",
    "#   if len(out_abc)==5:\n",
    "#     abcStr = ('M:5/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#         'snm=\"wh\"\\n[{}] [{}] [{}] [{}] [{}] ||\\nV:2 name=\"piano\" '.format\\\n",
    "#         (out_abc[0], out_abc[1], out_abc[2], out_abc[3],out_abc[4]))\n",
    "#   elif len(out_abc)==4:\n",
    "#       abcStr = ('M:4/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#         'snm=\"wh\"\\n[{}] [{}] [{}] [{}]||\\nV:2 name=\"piano\" '.format\\\n",
    "#         (out_abc[0], out_abc[1], out_abc[2], out_abc[3]))\n",
    "#   elif len(out_abc)==3:\n",
    "#       abcStr = ('M:3/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#         'snm=\"wh\"\\n[{}] [{}] [{}]||\\nV:2 name=\"piano\" '.format\\\n",
    "#         (out_abc[0], out_abc[1], out_abc[2]))\n",
    "#   elif len(out_abc)==2:\n",
    "#       abcStr = ('M:2/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#         'snm=\"wh\"\\n[{}] [{}]||\\nV:2 name=\"piano\" '.format\\\n",
    "#         (out_abc[0], out_abc[1]))\n",
    "#   elif len(out_abc)==1:\n",
    "#       abcStr = ('M:4/4\\nL:1/8\\nK:C\\nV:1 name=\"Whistle\" ' +\n",
    "#         'snm=\"wh\"\\n[{}] ||\\nV:2 name=\"piano\" '.format(out_abc[0]))\n",
    "#   out = music21.converter.parse(abcStr).write(\"midi\")\n",
    "#   ie = str(i)\n",
    "#   o = 'bach_out/test_5/{}.wav'.format(i)\n",
    "#   !fluidsynth -ni font.sf2 $out -F $o -r 44100\n",
    "#   from IPython.display import Audio\n",
    "#   Audio('bach_out/test_5/{}.wav'.format(i))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "seq2seq_mod.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
