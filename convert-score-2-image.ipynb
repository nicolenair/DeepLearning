{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import os\n",
    "os.environ[\"musescoreDirectPNGPath\"] = \"/Applications/MuseScore\\ 3/bin/MuseScore.exe\"\n",
    "os.environ[\"musicxmlPath\"] = \"/Applications/MuseScore\\ 3/bin/MuseScore.exe\"\n",
    "song = music21.converter.parse('bach/chor002.midi')\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "#import necessary modules, and set path to use musescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split images according to criterion specified\n",
    "#i.e. four quarter notes per image\n",
    "#then save to file \n",
    "songs = []\n",
    "for i in range(1, 111):\n",
    "    if len(str(i))==1:\n",
    "        e = \"00\" + str(i)\n",
    "    elif len(str(i))==2:\n",
    "        e = \"0\" + str(i)\n",
    "    else:\n",
    "        e = str(i)\n",
    "    song = music21.converter.parse('Downloads/chor{}.mid'.format(e))\n",
    "    \n",
    "    for voice in range(len(song)):\n",
    "        prev = 0\n",
    "        for note in range(len(song[voice].notes)):\n",
    "            if song[voice].notes.stream()[:note].highestOffset%3==0 and \\\n",
    "            song[voice].notes.stream()[:note].highestOffset>0:\n",
    "                s1 = music21.stream.Stream()\n",
    "                for k in range(prev, note):\n",
    "                    s1.append(song[voice].notes.stream()[k])\n",
    "                prev = note\n",
    "                tmp_path = s1.write(fmt = 'musicxml.png')\n",
    "                #write to permanent file, \n",
    "                #a hack bc music21's path specifying feature does not work for me\n",
    "                in_ = open(tmp_path, \"rb\")\n",
    "                with open(\"bach/img{}.png\".format(e+str(voice)+str(note)), \"wb\")\\\n",
    "                as file:\n",
    "                    file.write(in_.read())\n",
    "\n",
    "        in_.close()\n",
    "                          \n",
    "    \n",
    "#         break\n",
    "        \n",
    "#         song.flat.notes.stream()[:10].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally, the png images have \"transparencies\"\n",
    "#which need to be changed into white pixels \n",
    "#(a gap in the PIL functionality that PyTorch uses)\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "for i in os.listdir(\"bach\"):\n",
    "    if re.match(\"img\\d+.png\", i) != None:\n",
    "        # Load the image and make into Numpy array\n",
    "        rgba = np.array(Image.open(\"bach/\" + i))\n",
    "\n",
    "        # Make image transparent white anywhere it is transparent\n",
    "        rgba[rgba[...,-1]==0] = [255,255,255,0]\n",
    "\n",
    "        # Make back into PIL Image and save\n",
    "        Image.fromarray(rgba).save(\"bach/\" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#making labels for cgan\n",
    "songs = []\n",
    "file = open(\"labels.txt\", \"a+\")\n",
    "t = 0\n",
    "for i in range(78, 79):\n",
    "    if len(str(i))==1:\n",
    "        e = \"00\" + str(i)\n",
    "    elif len(str(i))==2:\n",
    "        e = \"0\" + str(i)\n",
    "    else:\n",
    "        e = str(i)\n",
    "    song = music21.converter.parse('bach2/chor{}.midi'.format(e))\n",
    "    \n",
    "    for voice in range(len(song)):\n",
    "        prev = 0\n",
    "        for note in range(len(song[voice].notes)):\n",
    "            if song[voice].notes.stream()[:note].highestOffset%3==0 and\\\n",
    "            song[voice].notes.stream()[:note].highestOffset>0:\n",
    "                s1 = music21.stream.Stream()\n",
    "                for k in range(prev, note):\n",
    "                    s1.append(song[voice].notes.stream()[k])\n",
    "                if str(song[voice].notes.stream()[prev])[-2]==\"#\" \\\n",
    "                or str(song[voice].notes.stream()[prev])[-2]==\"-\":\n",
    "                    file.write(e+str(voice)+str(note) + \"\\t\" + \\\n",
    "                               str(song[voice].notes.stream()[prev])[-3:-1])\n",
    "                else:\n",
    "                    file.write(e+str(voice)+str(note) + \"\\t\" + \\\n",
    "                               str(song[voice].notes.stream()[prev])[-2])\n",
    "                file.write(\"\\n\")\n",
    "                t+=1\n",
    "#                 print(str(song[voice].notes.stream()[prev])[-2])\n",
    "                prev = note\n",
    "#                 tmp_path = s1.write(fmt = 'musicxml.png')\n",
    "                \n",
    "\n",
    "file.close()\n",
    "\n",
    "#         in_.close()\n",
    "                          \n",
    "    \n",
    "#         break\n",
    "        \n",
    "#         song.flat.notes.stream()[:10].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
